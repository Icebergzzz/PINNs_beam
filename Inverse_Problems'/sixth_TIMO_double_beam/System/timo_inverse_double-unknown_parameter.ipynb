{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informal-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exact solution (Phi1)\n",
    "def exact_solution_u(x, t):\n",
    "    return (pi/2*torch.cos(x) + (x-pi/2))*torch.cos(t)\n",
    "\n",
    "def initial_condition_u(x):\n",
    "    return (pi/2*torch.cos(x) + (x-pi/2))\n",
    "\n",
    "def initial_condition_u_t(x):\n",
    "    return 0.0*pi*torch.cos(x) \n",
    "\n",
    "# Define the exact solution(w1)\n",
    "def exact_solution_p(x, t):\n",
    "    return pi/2*torch.sin(x)*torch.cos(t)\n",
    "\n",
    "def initial_condition_p(x):\n",
    "    return pi/2*torch.sin(x)\n",
    "\n",
    "def initial_condition_p_t(x):\n",
    "    return 0*torch.sin(x) \n",
    "\n",
    "# Define the exact solution (Phi1)\n",
    "def exact_solution_u1(x, t):\n",
    "    return (2/pi)*(pi/2*torch.cos(x) + (x-pi/2))*torch.cos(t)\n",
    "\n",
    "def initial_condition_u1(x):\n",
    "    return (2/pi)*(pi/2*torch.cos(x) + (x-pi/2))\n",
    "\n",
    "def initial_condition_u_t1(x):\n",
    "    return 0.0*pi*torch.cos(x) \n",
    "\n",
    "# Define the exact solution(w1)\n",
    "def exact_solution_p1(x, t):\n",
    "    return torch.sin(x)*torch.cos(t)\n",
    "\n",
    "def initial_condition_p1(x):\n",
    "    return torch.sin(x)\n",
    "\n",
    "def initial_condition_p_t1(x):\n",
    "    return 0*torch.sin(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86dcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a80b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b615be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_u1 = pd.read_csv(r'timo_data_u1_inverse.csv', header = None)\n",
    "inp_u2 = pd.read_csv(r'timo_data_u2_inverse.csv', header = None)\n",
    "inp_u3 = pd.read_csv(r'timo_data_u3_inverse.csv', header = None)\n",
    "inp_u4 = pd.read_csv(r'timo_data_u4_inverse.csv', header = None)\n",
    "inp_u5 = pd.read_csv(r'timo_data_u5_inverse.csv', header = None)\n",
    "inp_u6 = pd.read_csv(r'timo_data_u6_inverse.csv', header = None)\n",
    "inp_u7 = pd.read_csv(r'timo_data_u7_inverse.csv', header = None)\n",
    "inp_u8 = pd.read_csv(r'timo_data_u8_inverse.csv', header = None)\n",
    "inp_u9 = pd.read_csv(r'timo_data_u9_inverse.csv', header = None)\n",
    "inp_u10 = pd.read_csv(r'timo_data_u10_inverse.csv', header = None)\n",
    "inp_u11 = pd.read_csv(r'timo_data_u11_inverse.csv', header = None)\n",
    "inp_u12 = pd.read_csv(r'timo_data_u12_inverse.csv', header = None)\n",
    "inp_u13 = pd.read_csv(r'timo_data_u13_inverse.csv', header = None)\n",
    "inp_u14 = pd.read_csv(r'timo_data_u14_inverse.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966c63ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_p1 = pd.read_csv(r'timo_data_p1_inverse.csv', header = None)\n",
    "inp_p2 = pd.read_csv(r'timo_data_p2_inverse.csv', header = None)\n",
    "inp_p3 = pd.read_csv(r'timo_data_p3_inverse.csv', header = None)\n",
    "inp_p4 = pd.read_csv(r'timo_data_p4_inverse.csv', header = None)\n",
    "inp_p5 = pd.read_csv(r'timo_data_p5_inverse.csv', header = None)\n",
    "inp_p6 = pd.read_csv(r'timo_data_p6_inverse.csv', header = None)\n",
    "inp_p7 = pd.read_csv(r'timo_data_p7_inverse.csv', header = None)\n",
    "inp_p8 = pd.read_csv(r'timo_data_p8_inverse.csv', header = None)\n",
    "inp_p9 = pd.read_csv(r'timo_data_p9_inverse.csv', header = None)\n",
    "inp_p10 = pd.read_csv(r'timo_data_p10_inverse.csv', header = None)\n",
    "inp_p11 = pd.read_csv(r'timo_data_p11_inverse.csv', header = None)\n",
    "inp_p12 = pd.read_csv(r'timo_data_p12_inverse.csv', header = None)\n",
    "inp_p13 = pd.read_csv(r'timo_data_p13_inverse.csv', header = None)\n",
    "inp_p14 = pd.read_csv(r'timo_data_p14_inverse.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14abf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_q1 = pd.read_csv(r'timo_data_q1_inverse.csv', header = None)\n",
    "inp_q2 = pd.read_csv(r'timo_data_q2_inverse.csv', header = None)\n",
    "inp_q3 = pd.read_csv(r'timo_data_q3_inverse.csv', header = None)\n",
    "inp_q4 = pd.read_csv(r'timo_data_q4_inverse.csv', header = None)\n",
    "inp_q5 = pd.read_csv(r'timo_data_q5_inverse.csv', header = None)\n",
    "inp_q6 = pd.read_csv(r'timo_data_q6_inverse.csv', header = None)\n",
    "inp_q7 = pd.read_csv(r'timo_data_q7_inverse.csv', header = None)\n",
    "inp_q8 = pd.read_csv(r'timo_data_q8_inverse.csv', header = None)\n",
    "inp_q9 = pd.read_csv(r'timo_data_q9_inverse.csv', header = None)\n",
    "inp_q10 = pd.read_csv(r'timo_data_q10_inverse.csv', header = None)\n",
    "inp_q11 = pd.read_csv(r'timo_data_q11_inverse.csv', header = None)\n",
    "inp_q12 = pd.read_csv(r'timo_data_q12_inverse.csv', header = None)\n",
    "inp_q13 = pd.read_csv(r'timo_data_q13_inverse.csv', header = None)\n",
    "inp_q14 = pd.read_csv(r'timo_data_q14_inverse.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc15cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_r1 = pd.read_csv(r'timo_data_r1_inverse.csv', header = None)\n",
    "inp_r2 = pd.read_csv(r'timo_data_r2_inverse.csv', header = None)\n",
    "inp_r3 = pd.read_csv(r'timo_data_r3_inverse.csv', header = None)\n",
    "inp_r4 = pd.read_csv(r'timo_data_r4_inverse.csv', header = None)\n",
    "inp_r5 = pd.read_csv(r'timo_data_r5_inverse.csv', header = None)\n",
    "inp_r6 = pd.read_csv(r'timo_data_r6_inverse.csv', header = None)\n",
    "inp_r7 = pd.read_csv(r'timo_data_r7_inverse.csv', header = None)\n",
    "inp_r8 = pd.read_csv(r'timo_data_r8_inverse.csv', header = None)\n",
    "inp_r9 = pd.read_csv(r'timo_data_r9_inverse.csv', header = None)\n",
    "inp_r10 = pd.read_csv(r'timo_data_r10_inverse.csv', header = None)\n",
    "inp_r11 = pd.read_csv(r'timo_data_r11_inverse.csv', header = None)\n",
    "inp_r12 = pd.read_csv(r'timo_data_r12_inverse.csv', header = None)\n",
    "inp_r13 = pd.read_csv(r'timo_data_r13_inverse.csv', header = None)\n",
    "inp_r14 = pd.read_csv(r'timo_data_r14_inverse.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350c526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_u1 = inp_u1[::20]\n",
    "inp_u2 = inp_u2[::20]\n",
    "inp_u3 = inp_u3[::20]\n",
    "inp_u4 = inp_u4[::20]\n",
    "inp_u5 = inp_u5[::20]\n",
    "inp_u6 = inp_u6[::20]\n",
    "inp_u7 = inp_u7[::20]\n",
    "inp_u8 = inp_u8[::20]\n",
    "inp_u9 = inp_u9[::20]\n",
    "inp_u10 = inp_u10[::20]\n",
    "inp_u11 = inp_u11[::20]\n",
    "inp_u12 = inp_u12[::20]\n",
    "inp_u13 = inp_u13[::20]\n",
    "inp_u14 = inp_u14[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0963ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_p1 = inp_p1[::20]\n",
    "inp_p2 = inp_p2[::20]\n",
    "inp_p3 = inp_p3[::20]\n",
    "inp_p4 = inp_p4[::20]\n",
    "inp_p5 = inp_p5[::20]\n",
    "inp_p6 = inp_p6[::20]\n",
    "inp_p7 = inp_p7[::20]\n",
    "inp_p8 = inp_p8[::20]\n",
    "inp_p9 = inp_p9[::20]\n",
    "inp_p10 = inp_p10[::20]\n",
    "inp_p11 = inp_p11[::20]\n",
    "inp_p12 = inp_p12[::20]\n",
    "inp_p13 = inp_p13[::20]\n",
    "inp_p14 = inp_p14[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04eb4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_q1 = inp_q1[::20]\n",
    "inp_q2 = inp_q2[::20]\n",
    "inp_q3 = inp_q3[::20]\n",
    "inp_q4 = inp_q4[::20]\n",
    "inp_q5 = inp_q5[::20]\n",
    "inp_q6 = inp_q6[::20]\n",
    "inp_q7 = inp_q7[::20]\n",
    "inp_q8 = inp_q8[::20]\n",
    "inp_q9 = inp_q9[::20]\n",
    "inp_q10 = inp_q10[::20]\n",
    "inp_q11 = inp_q11[::20]\n",
    "inp_q12 = inp_q12[::20]\n",
    "inp_q13 = inp_q13[::20]\n",
    "inp_q14 = inp_q14[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ed3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_r1 = inp_r1[::20]\n",
    "inp_r2 = inp_r2[::20]\n",
    "inp_r3 = inp_r3[::20]\n",
    "inp_r4 = inp_r4[::20]\n",
    "inp_r5 = inp_r5[::20]\n",
    "inp_r6 = inp_r6[::20]\n",
    "inp_r7 = inp_r7[::20]\n",
    "inp_r8 = inp_r8[::20]\n",
    "inp_r9 = inp_r9[::20]\n",
    "inp_r10 = inp_r10[::20]\n",
    "inp_r11 = inp_r11[::20]\n",
    "inp_r12 = inp_r12[::20]\n",
    "inp_r13 = inp_r13[::20]\n",
    "inp_r14 = inp_r14[::20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f2c98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        ...,\n",
      "        [0.2000],\n",
      "        [0.2000],\n",
      "        [0.2000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u1 = inp_u1.to_numpy()\n",
    "inputs_p1 = inp_p1.to_numpy()\n",
    "inputs_q1 = inp_q1.to_numpy()\n",
    "inputs_r1 = inp_r1.to_numpy()\n",
    "data_t1 = inputs_u1[:,0].astype(np.float32)\n",
    "data_x1 = inputs_u1[:,1].astype(np.float32)\n",
    "data_u1 = inputs_u1[:,2].astype(np.float32)\n",
    "data_p1 = inputs_p1[:,2].astype(np.float32)\n",
    "\n",
    "data_q1 = inputs_q1[:,2].astype(np.float32)\n",
    "data_r1 = inputs_r1[:,2].astype(np.float32)\n",
    "\n",
    "data_t1 = data_t1.reshape(-1, 1)\n",
    "data_x1 = data_x1.reshape(-1, 1)\n",
    "data_u1 = data_u1.reshape(-1, 1)\n",
    "data_p1 = data_p1.reshape(-1, 1)\n",
    "data_q1 = data_q1.reshape(-1, 1)\n",
    "data_r1 = data_r1.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "data_t1 = torch.from_numpy(data_t1)\n",
    "data_x1 = torch.from_numpy(data_x1)\n",
    "data_u1 = torch.from_numpy(data_u1)\n",
    "data_p1 = torch.from_numpy(data_p1)\n",
    "data_q1 = torch.from_numpy(data_q1)\n",
    "data_r1 = torch.from_numpy(data_r1)\n",
    "data_inp1 = torch.cat([data_x1, data_t1],1)\n",
    "print(data_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca973f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        ...,\n",
      "        [0.4000],\n",
      "        [0.4000],\n",
      "        [0.4000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u2 = inp_u2.to_numpy()\n",
    "inputs_p2 = inp_p2.to_numpy()\n",
    "inputs_q2 = inp_q2.to_numpy()\n",
    "inputs_r2 = inp_r2.to_numpy()\n",
    "data_t2 = inputs_u2[:,0].astype(np.float32)\n",
    "data_x2 = inputs_u2[:,1].astype(np.float32)\n",
    "data_u2 = inputs_u2[:,2].astype(np.float32)\n",
    "data_p2 = inputs_p2[:,2].astype(np.float32)\n",
    "data_q2 = inputs_q2[:,2].astype(np.float32)\n",
    "data_r2 = inputs_r2[:,2].astype(np.float32)\n",
    "\n",
    "data_t2 = data_t2.reshape(-1, 1)\n",
    "data_x2 = data_x2.reshape(-1, 1)\n",
    "data_u2 = data_u2.reshape(-1, 1)\n",
    "data_p2 = data_u2.reshape(-1, 1)\n",
    "data_q2 = data_u2.reshape(-1, 1)\n",
    "data_r2 = data_r2.reshape(-1, 1)\n",
    "\n",
    "data_t2 = torch.from_numpy(data_t2)\n",
    "data_x2 = torch.from_numpy(data_x2)\n",
    "data_u2 = torch.from_numpy(data_u2)\n",
    "data_p2 = torch.from_numpy(data_p2)\n",
    "data_q2 = torch.from_numpy(data_q2)\n",
    "data_r2 = torch.from_numpy(data_r2)\n",
    "\n",
    "data_inp2 = torch.cat([data_x2, data_t2],1)\n",
    "print(data_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15c9fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6000],\n",
      "        [0.6000],\n",
      "        [0.6000],\n",
      "        ...,\n",
      "        [0.6000],\n",
      "        [0.6000],\n",
      "        [0.6000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u3 = inp_u3.to_numpy()\n",
    "inputs_p3 = inp_p3.to_numpy()\n",
    "inputs_q3 = inp_q3.to_numpy()\n",
    "inputs_r3 = inp_r3.to_numpy()\n",
    "data_t3 = inputs_u3[:,0].astype(np.float32)\n",
    "data_x3 = inputs_u3[:,1].astype(np.float32)\n",
    "data_u3 = inputs_u3[:,2].astype(np.float32)\n",
    "data_q3 = inputs_q3[:,2].astype(np.float32)\n",
    "data_r3 = inputs_r3[:,2].astype(np.float32)\n",
    "data_p3 = inputs_p3[:,2].astype(np.float32)\n",
    "data_t3 = data_t3.reshape(-1, 1)\n",
    "data_x3 = data_x3.reshape(-1, 1)\n",
    "data_u3 = data_u3.reshape(-1, 1)\n",
    "data_p3 = data_p3.reshape(-1, 1)\n",
    "data_q3 = data_q3.reshape(-1, 1)\n",
    "data_r3 = data_r3.reshape(-1, 1)\n",
    "data_t3 = torch.from_numpy(data_t3)\n",
    "data_x3 = torch.from_numpy(data_x3)\n",
    "data_u3 = torch.from_numpy(data_u3)\n",
    "data_p3 = torch.from_numpy(data_p3)\n",
    "data_q3 = torch.from_numpy(data_q3)\n",
    "data_r3 = torch.from_numpy(data_r3)\n",
    "data_inp3 = torch.cat([data_x3, data_t3],1)\n",
    "print(data_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6eaf466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8000],\n",
      "        [0.8000],\n",
      "        [0.8000],\n",
      "        ...,\n",
      "        [0.8000],\n",
      "        [0.8000],\n",
      "        [0.8000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u4 = inp_u4.to_numpy()\n",
    "inputs_p4 = inp_p4.to_numpy()\n",
    "inputs_q4 = inp_q4.to_numpy()\n",
    "inputs_r4 = inp_r4.to_numpy()\n",
    "data_t4 = inputs_u4[:,0].astype(np.float32)\n",
    "data_x4 = inputs_u4[:,1].astype(np.float32)\n",
    "data_u4 = inputs_u4[:,2].astype(np.float32)\n",
    "data_p4 = inputs_p4[:,2].astype(np.float32)\n",
    "data_q4 = inputs_q4[:,2].astype(np.float32)\n",
    "data_r4 = inputs_r4[:,2].astype(np.float32)\n",
    "\n",
    "\n",
    "data_t4 = data_t4.reshape(-1, 1)\n",
    "data_x4 = data_x4.reshape(-1, 1)\n",
    "data_u4 = data_u4.reshape(-1, 1)\n",
    "data_p4 = data_p4.reshape(-1, 1)\n",
    "data_q4 = data_q4.reshape(-1, 1)\n",
    "data_r4 = data_r4.reshape(-1, 1)\n",
    "\n",
    "data_t4 = torch.from_numpy(data_t4)\n",
    "data_x4 = torch.from_numpy(data_x4)\n",
    "data_u4 = torch.from_numpy(data_u4)\n",
    "data_p4 = torch.from_numpy(data_p4)\n",
    "data_q4 = torch.from_numpy(data_q4)\n",
    "data_r4 = torch.from_numpy(data_r4)\n",
    "data_inp4 = torch.cat([data_x4, data_t4],1)\n",
    "print(data_x4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0b3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_u5 = inp_u5.to_numpy()\n",
    "inputs_p5 = inp_p5.to_numpy()\n",
    "inputs_q5 = inp_q5.to_numpy()\n",
    "inputs_r5 = inp_r5.to_numpy()\n",
    "data_t5 = inputs_u5[:,0].astype(np.float32)\n",
    "data_x5 = inputs_u5[:,1].astype(np.float32)\n",
    "data_u5 = inputs_u5[:,2].astype(np.float32)\n",
    "data_p5 = inputs_p5[:,2].astype(np.float32)\n",
    "data_q5 = inputs_q5[:,2].astype(np.float32)\n",
    "data_r5 = inputs_r5[:,2].astype(np.float32)\n",
    "\n",
    "data_t5 = data_t5.reshape(-1, 1)\n",
    "data_x5 = data_x5.reshape(-1, 1)\n",
    "data_u5 = data_u5.reshape(-1, 1)\n",
    "data_p5 = data_p5.reshape(-1, 1)\n",
    "data_q5 = data_q5.reshape(-1, 1)\n",
    "data_r5 = data_r5.reshape(-1, 1)\n",
    "\n",
    "data_t5 = torch.from_numpy(data_t5)\n",
    "data_x5 = torch.from_numpy(data_x5)\n",
    "data_u5 = torch.from_numpy(data_u5)\n",
    "data_p5 = torch.from_numpy(data_p5)\n",
    "data_q5 = torch.from_numpy(data_q5)\n",
    "data_r5 = torch.from_numpy(data_r5)\n",
    "data_inp5 = torch.cat([data_x5, data_t5],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db3ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2000],\n",
      "        [1.2000],\n",
      "        [1.2000],\n",
      "        ...,\n",
      "        [1.2000],\n",
      "        [1.2000],\n",
      "        [1.2000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u6 = inp_u6.to_numpy()\n",
    "inputs_p6 = inp_p6.to_numpy()\n",
    "inputs_q6 = inp_q6.to_numpy()\n",
    "inputs_r6 = inp_r6.to_numpy()\n",
    "data_t6 = inputs_u6[:,0].astype(np.float32)\n",
    "data_x6 = inputs_u6[:,1].astype(np.float32)\n",
    "data_u6 = inputs_u6[:,2].astype(np.float32)\n",
    "data_p6 = inputs_p6[:,2].astype(np.float32)\n",
    "data_q6 = inputs_q6[:,2].astype(np.float32)\n",
    "data_r6 = inputs_r6[:,2].astype(np.float32)\n",
    "\n",
    "data_t6 = data_t6.reshape(-1, 1)\n",
    "data_x6 = data_x6.reshape(-1, 1)\n",
    "data_u6 = data_u6.reshape(-1, 1)\n",
    "data_p6 = data_p6.reshape(-1, 1)\n",
    "data_q6 = data_q6.reshape(-1, 1)\n",
    "data_r6 = data_r6.reshape(-1, 1)\n",
    "\n",
    "data_t6 = torch.from_numpy(data_t6)\n",
    "data_x6 = torch.from_numpy(data_x6)\n",
    "data_u6 = torch.from_numpy(data_u6)\n",
    "data_p6 = torch.from_numpy(data_p6)\n",
    "data_q6 = torch.from_numpy(data_q6)\n",
    "data_r6 = torch.from_numpy(data_r6)\n",
    "\n",
    "data_inp6 = torch.cat([data_x6, data_t6],1)\n",
    "print(data_x6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abd3e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6000],\n",
      "        [1.6000],\n",
      "        [1.6000],\n",
      "        ...,\n",
      "        [1.6000],\n",
      "        [1.6000],\n",
      "        [1.6000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u7 = inp_u7.to_numpy()\n",
    "inputs_p7 = inp_p7.to_numpy()\n",
    "inputs_q7 = inp_q7.to_numpy()\n",
    "inputs_r7 = inp_r7.to_numpy()\n",
    "data_t7 = inputs_u7[:,0].astype(np.float32)\n",
    "data_x7 = inputs_u7[:,1].astype(np.float32)\n",
    "data_u7 = inputs_u7[:,2].astype(np.float32)\n",
    "data_p7 = inputs_p7[:,2].astype(np.float32)\n",
    "data_q7 = inputs_q7[:,2].astype(np.float32)\n",
    "data_r7 = inputs_r7[:,2].astype(np.float32)\n",
    "\n",
    "\n",
    "data_t7 = data_t7.reshape(-1, 1)\n",
    "data_x7 = data_x7.reshape(-1, 1)\n",
    "data_u7 = data_u7.reshape(-1, 1)\n",
    "data_p7 = data_p7.reshape(-1, 1)\n",
    "data_q7 = data_q7.reshape(-1, 1)\n",
    "data_r7 = data_r7.reshape(-1, 1)\n",
    "\n",
    "data_t7 = torch.from_numpy(data_t7)\n",
    "data_x7 = torch.from_numpy(data_x7)\n",
    "data_u7 = torch.from_numpy(data_u7)\n",
    "data_p7 = torch.from_numpy(data_p7)\n",
    "data_q7 = torch.from_numpy(data_q7)\n",
    "data_r7 = torch.from_numpy(data_r7)\n",
    "\n",
    "data_inp7 = torch.cat([data_x7, data_t7],1)\n",
    "print(data_x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16257aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8000],\n",
      "        [1.8000],\n",
      "        [1.8000],\n",
      "        ...,\n",
      "        [1.8000],\n",
      "        [1.8000],\n",
      "        [1.8000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u8 = inp_u8.to_numpy()\n",
    "inputs_p8 = inp_p8.to_numpy()\n",
    "inputs_q8 = inp_q8.to_numpy()\n",
    "inputs_r8 = inp_r8.to_numpy()\n",
    "data_t8 = inputs_u8[:,0].astype(np.float32)\n",
    "data_x8 = inputs_u8[:,1].astype(np.float32)\n",
    "data_u8 = inputs_u8[:,2].astype(np.float32)\n",
    "data_p8 = inputs_p8[:,2].astype(np.float32)\n",
    "data_q8 = inputs_q8[:,2].astype(np.float32)\n",
    "data_r8 = inputs_r8[:,2].astype(np.float32)\n",
    "data_t8 = data_t8.reshape(-1, 1)\n",
    "data_x8 = data_x8.reshape(-1, 1)\n",
    "data_u8 = data_u8.reshape(-1, 1)\n",
    "data_p8 = data_p8.reshape(-1, 1)\n",
    "data_q8 = data_q8.reshape(-1, 1)\n",
    "data_r8 = data_r8.reshape(-1, 1)\n",
    "\n",
    "\n",
    "data_t8 = torch.from_numpy(data_t8)\n",
    "data_x8 = torch.from_numpy(data_x8)\n",
    "data_u8 = torch.from_numpy(data_u8)\n",
    "data_p8 = torch.from_numpy(data_p8)\n",
    "data_q8 = torch.from_numpy(data_q8)\n",
    "data_r8 = torch.from_numpy(data_r8)\n",
    "data_inp8 = torch.cat([data_x8, data_t8],1)\n",
    "print(data_x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "427502f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        ...,\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u9 = inp_u9.to_numpy()\n",
    "inputs_p9 = inp_p9.to_numpy()\n",
    "inputs_q9 = inp_q9.to_numpy()\n",
    "inputs_r9 = inp_r9.to_numpy()\n",
    "\n",
    "data_t9 = inputs_u9[:,0].astype(np.float32)\n",
    "data_x9 = inputs_u9[:,1].astype(np.float32)\n",
    "\n",
    "data_u9 = inputs_u9[:,2].astype(np.float32)\n",
    "data_p9 = inputs_p9[:,2].astype(np.float32)\n",
    "data_q9 = inputs_q9[:,2].astype(np.float32)\n",
    "data_r9 = inputs_r9[:,2].astype(np.float32)\n",
    "\n",
    "data_t9 = data_t9.reshape(-1, 1)\n",
    "data_x9 = data_x9.reshape(-1, 1)\n",
    "data_u9 = data_u9.reshape(-1, 1)\n",
    "data_p9 = data_p9.reshape(-1, 1)\n",
    "data_q9 = data_q9.reshape(-1, 1)\n",
    "data_r9 = data_r9.reshape(-1, 1)\n",
    "\n",
    "data_t9 = torch.from_numpy(data_t9)\n",
    "data_x9 = torch.from_numpy(data_x9)\n",
    "data_u9 = torch.from_numpy(data_u9)\n",
    "data_p9 = torch.from_numpy(data_p9)\n",
    "data_q9 = torch.from_numpy(data_q9)\n",
    "data_r9 = torch.from_numpy(data_r9)\n",
    "data_inp9 = torch.cat([data_x9, data_t9],1)\n",
    "print(data_x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6511dfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2000],\n",
      "        [2.2000],\n",
      "        [2.2000],\n",
      "        ...,\n",
      "        [2.2000],\n",
      "        [2.2000],\n",
      "        [2.2000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u10 = inp_u10.to_numpy()\n",
    "inputs_p10 = inp_p10.to_numpy()\n",
    "inputs_q10 = inp_q10.to_numpy()\n",
    "inputs_r10 = inp_r10.to_numpy()\n",
    "\n",
    "data_t10 = inputs_u10[:,0].astype(np.float32)\n",
    "data_x10 = inputs_u10[:,1].astype(np.float32)\n",
    "data_u10 = inputs_u10[:,2].astype(np.float32)\n",
    "data_p10 = inputs_p10[:,2].astype(np.float32)\n",
    "data_q10 = inputs_q10[:,2].astype(np.float32)\n",
    "data_r10 = inputs_r10[:,2].astype(np.float32)\n",
    "\n",
    "data_t10 = data_t10.reshape(-1, 1)\n",
    "data_x10 = data_x10.reshape(-1, 1)\n",
    "data_u10 = data_u10.reshape(-1, 1)\n",
    "data_p10 = data_p10.reshape(-1, 1)\n",
    "data_q10 = data_q10.reshape(-1, 1)\n",
    "data_r10 = data_r10.reshape(-1, 1)\n",
    "\n",
    "data_t10 = torch.from_numpy(data_t10)\n",
    "data_x10 = torch.from_numpy(data_x10)\n",
    "data_u10 = torch.from_numpy(data_u10)\n",
    "data_p10 = torch.from_numpy(data_p10)\n",
    "data_q10 = torch.from_numpy(data_q10)\n",
    "data_r10 = torch.from_numpy(data_r10)\n",
    "data_inp10 = torch.cat([data_x10, data_t10],1)\n",
    "print(data_x10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a998c053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.4000],\n",
      "        [2.4000],\n",
      "        [2.4000],\n",
      "        ...,\n",
      "        [2.4000],\n",
      "        [2.4000],\n",
      "        [2.4000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u11 = inp_u11.to_numpy()\n",
    "inputs_p11 = inp_p11.to_numpy()\n",
    "inputs_q11 = inp_q11.to_numpy()\n",
    "inputs_r11 = inp_r11.to_numpy()\n",
    "\n",
    "data_t11 = inputs_u11[:,0].astype(np.float32)\n",
    "data_x11 = inputs_u11[:,1].astype(np.float32)\n",
    "data_u11 = inputs_u11[:,2].astype(np.float32)\n",
    "data_p11 = inputs_p11[:,2].astype(np.float32)\n",
    "data_q11 = inputs_q11[:,2].astype(np.float32)\n",
    "data_r11 = inputs_r11[:,2].astype(np.float32)\n",
    "\n",
    "\n",
    "data_t11 = data_t11.reshape(-1, 1)\n",
    "data_x11 = data_x11.reshape(-1, 1)\n",
    "data_u11 = data_u11.reshape(-1, 1)\n",
    "data_p11 = data_p11.reshape(-1, 1)\n",
    "data_q11 = data_q11.reshape(-1, 1)\n",
    "data_r11 = data_r11.reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_t11 = torch.from_numpy(data_t11)\n",
    "data_x11 = torch.from_numpy(data_x11)\n",
    "data_u11 = torch.from_numpy(data_u11)\n",
    "data_p11 = torch.from_numpy(data_p11)\n",
    "data_q11 = torch.from_numpy(data_q11)\n",
    "data_r11 = torch.from_numpy(data_r11)\n",
    "\n",
    "data_inp11 = torch.cat([data_x11, data_t11],1)\n",
    "print(data_x11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffaf2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef5dcaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6000],\n",
      "        [2.6000],\n",
      "        [2.6000],\n",
      "        ...,\n",
      "        [2.6000],\n",
      "        [2.6000],\n",
      "        [2.6000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u12 = inp_u12.to_numpy()\n",
    "inputs_p12 = inp_p12.to_numpy()\n",
    "inputs_q12 = inp_q12.to_numpy()\n",
    "inputs_r12 = inp_r12.to_numpy()\n",
    "\n",
    "data_t12 = inputs_u12[:,0].astype(np.float32)\n",
    "data_x12 = inputs_u12[:,1].astype(np.float32)\n",
    "data_u12 = inputs_u12[:,2].astype(np.float32)\n",
    "data_p12 = inputs_p12[:,2].astype(np.float32)\n",
    "data_q12 = inputs_q12[:,2].astype(np.float32)\n",
    "data_r12 = inputs_r12[:,2].astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "data_t12 = data_t12.reshape(-1, 1)\n",
    "data_x12 = data_x12.reshape(-1, 1)\n",
    "data_u12 = data_u12.reshape(-1, 1)\n",
    "data_p12 = data_p12.reshape(-1, 1)\n",
    "data_q12 = data_q12.reshape(-1, 1)\n",
    "data_r12 = data_r12.reshape(-1, 1)\n",
    "\n",
    "data_t12 = torch.from_numpy(data_t12)\n",
    "data_x12 = torch.from_numpy(data_x12)\n",
    "data_u12 = torch.from_numpy(data_u12)\n",
    "data_p12 = torch.from_numpy(data_p12)\n",
    "data_q12 = torch.from_numpy(data_q12)\n",
    "data_r12 = torch.from_numpy(data_r12)\n",
    "data_inp12 = torch.cat([data_x12, data_t12],1)\n",
    "print(data_x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bb9aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8000],\n",
      "        [2.8000],\n",
      "        [2.8000],\n",
      "        ...,\n",
      "        [2.8000],\n",
      "        [2.8000],\n",
      "        [2.8000]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u13 = inp_u13.to_numpy()\n",
    "inputs_p13 = inp_p13.to_numpy()\n",
    "inputs_q13 = inp_q13.to_numpy()\n",
    "inputs_r13 = inp_r13.to_numpy()\n",
    "\n",
    "data_t13 = inputs_u13[:,0].astype(np.float32)\n",
    "data_x13 = inputs_u13[:,1].astype(np.float32)\n",
    "data_u13 = inputs_u13[:,2].astype(np.float32)\n",
    "data_p13 = inputs_p13[:,2].astype(np.float32)\n",
    "data_q13 = inputs_q13[:,2].astype(np.float32)\n",
    "data_r13 = inputs_r13[:,2].astype(np.float32)\n",
    "\n",
    "data_t13 = data_t13.reshape(-1, 1)\n",
    "data_x13 = data_x13.reshape(-1, 1)\n",
    "data_u13 = data_u13.reshape(-1, 1)\n",
    "data_p13 = data_p13.reshape(-1, 1)\n",
    "data_q13 = data_q13.reshape(-1, 1)\n",
    "data_r13 = data_r13.reshape(-1, 1)\n",
    "\n",
    "data_t13 = torch.from_numpy(data_t13)\n",
    "data_x13 = torch.from_numpy(data_x13)\n",
    "data_u13 = torch.from_numpy(data_u13)\n",
    "data_p13 = torch.from_numpy(data_p13)\n",
    "data_q13 = torch.from_numpy(data_q13)\n",
    "data_r13 = torch.from_numpy(data_r13)\n",
    "data_inp13 = torch.cat([data_x13, data_t13],1)\n",
    "print(data_x13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4c25c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        ...,\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "inputs_u14 = inp_u14.to_numpy()\n",
    "inputs_p14 = inp_p14.to_numpy()\n",
    "inputs_q14 = inp_q14.to_numpy()\n",
    "inputs_r14 = inp_r14.to_numpy()\n",
    "\n",
    "data_t14 = inputs_u14[:,0].astype(np.float32)\n",
    "data_x14 = inputs_u14[:,1].astype(np.float32)\n",
    "data_u14 = inputs_u14[:,2].astype(np.float32)\n",
    "data_p14 = inputs_p14[:,2].astype(np.float32)\n",
    "data_q14 = inputs_q14[:,2].astype(np.float32)\n",
    "data_r14 = inputs_r14[:,2].astype(np.float32)\n",
    "\n",
    "data_t14 = data_t14.reshape(-1, 1)\n",
    "data_x14 = data_x14.reshape(-1, 1)\n",
    "data_u14 = data_u14.reshape(-1, 1)\n",
    "data_p14 = data_p14.reshape(-1, 1)\n",
    "data_q14 = data_q14.reshape(-1, 1)\n",
    "data_r14 = data_r14.reshape(-1, 1)\n",
    "\n",
    "data_t14 = torch.from_numpy(data_t14)\n",
    "data_x14 = torch.from_numpy(data_x14)\n",
    "data_u14 = torch.from_numpy(data_u14)\n",
    "data_p14 = torch.from_numpy(data_p14)\n",
    "data_q14 = torch.from_numpy(data_q14)\n",
    "data_r14 = torch.from_numpy(data_r14)\n",
    "data_inp14 = torch.cat([data_x14, data_t14],1)\n",
    "print(data_x14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd7af0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning number of points\n",
    "initial_pts = 200\n",
    "left_boundary_pts = 200\n",
    "right_boundary_pts = 200\n",
    "residual_pts = 1000\n",
    "# Type of optimizer (ADAM or LBFGS)\n",
    "opt_type = \"LBFGS\"\n",
    "manualSeed = 1\n",
    "\n",
    "#np.random.seed(manualSeed)\n",
    "#random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "x_init = pi*torch.rand((initial_pts,1)) # initial pts\n",
    "t_init = 0*x_init\n",
    "init =  torch.cat([x_init, t_init],1)\n",
    "u_init = initial_condition_u(init[:,0]).reshape(-1, 1)\n",
    "p_init = initial_condition_p(init[:,0]).reshape(-1, 1)\n",
    "u1_init = initial_condition_u1(init[:,0]).reshape(-1, 1)\n",
    "p1_init = initial_condition_p1(init[:,0]).reshape(-1, 1)\n",
    "w_init = torch.cat([u_init, p_init, u1_init, p1_init],1)\n",
    "\n",
    "u_t_init = initial_condition_u_t(init[:,0]).reshape(-1, 1)\n",
    "p_t_init = initial_condition_p_t(init[:,0]).reshape(-1, 1)\n",
    "u1_t_init = initial_condition_u_t1(init[:,0]).reshape(-1, 1)\n",
    "p1_t_init = initial_condition_p_t1(init[:,0]).reshape(-1, 1)\n",
    "w_t_init = torch.cat([u_t_init, p_t_init, u1_t_init, p1_t_init],1)\n",
    "\n",
    "\n",
    "\n",
    "xb_left = torch.zeros((left_boundary_pts, 1)) # left spatial boundary\n",
    "tb_left = torch.rand((left_boundary_pts, 1)) # \n",
    "b_left = torch.cat([xb_left, tb_left ],1)\n",
    "u_b_l = exact_solution_u(xb_left, tb_left)\n",
    "p_b_l = exact_solution_p(xb_left, tb_left)\n",
    "u1_b_l = exact_solution_u1(xb_left, tb_left)\n",
    "p1_b_l = exact_solution_p1(xb_left, tb_left)\n",
    "w_b_l = torch.cat([u_b_l, p_b_l, u1_b_l, p1_b_l],1)\n",
    "\n",
    "\n",
    "\n",
    "xb_right = pi*torch.ones((right_boundary_pts, 1)) # right spatial boundary\n",
    "tb_right = torch.rand((right_boundary_pts, 1)) # right boundary pts\n",
    "b_right = torch.cat([xb_right, tb_right ],1)\n",
    "u_b_r = exact_solution_u(xb_right, tb_right)\n",
    "p_b_r = exact_solution_p(xb_right, tb_right)\n",
    "u1_b_r = exact_solution_u1(xb_right, tb_right)\n",
    "p1_b_r = exact_solution_p1(xb_right, tb_right)\n",
    "w_b_r = torch.cat([u_b_r, p_b_r, u1_b_r, p1_b_r],1)\n",
    "\n",
    "x_interior = pi*torch.rand((residual_pts, 1))\n",
    "t_interior = torch.rand((residual_pts, 1))\n",
    "interior = torch.cat([x_interior, t_interior],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_set = DataLoader(torch.utils.data.TensorDataset(init, w_init, w_t_init, b_left,  b_right), batch_size=200, shuffle=False)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, output_dimension, n_hidden_layers, neurons):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Number of input dimensions n\n",
    "        self.input_dimension = input_dimension\n",
    "        # Number of output dimensions m\n",
    "        self.output_dimension = output_dimension\n",
    "        # Number of neurons per layer \n",
    "        self.neurons = neurons\n",
    "        # Number of hidden layers \n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        # Activation function \n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        self.input_layer = nn.Linear(self.input_dimension, self.neurons)\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(self.neurons, self.neurons) for _ in range(n_hidden_layers)])\n",
    "        self.output_layer = nn.Linear(self.neurons, self.output_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function performs the set of affine and non-linear transformations defining the network \n",
    "        # (see equation above)\n",
    "        x = self.activation(self.input_layer(x))\n",
    "        for k, l in enumerate(self.hidden_layers):\n",
    "            x = self.activation(l(x))\n",
    "        return self.output_layer(x)\n",
    "# Model definition\n",
    "my_network = NeuralNet(input_dimension = init.shape[1], output_dimension = 5, n_hidden_layers=4, neurons=20)\n",
    "\n",
    "def init_xavier(model, retrain_seed):\n",
    "    torch.manual_seed(retrain_seed)\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear and m.weight.requires_grad and m.bias.requires_grad:\n",
    "            g = nn.init.calculate_gain('tanh')\n",
    "            torch.nn.init.xavier_uniform_(m.weight, gain=g)\n",
    "            #torch.nn.init.xavier_normal_(m.weight, gain=g)\n",
    "            m.bias.data.fill_(0)\n",
    "    model.apply(init_weights)\n",
    "\n",
    "# Random Seed for weight initialization\n",
    "retrain = 128\n",
    "# Xavier weight initialization\n",
    "init_xavier(my_network, retrain)\n",
    "#print(my_network(init))\n",
    "\n",
    "if opt_type == \"ADAM\":\n",
    "    optimizer_ = optim.Adam(my_network.parameters(), lr=0.001)\n",
    "elif opt_type == \"LBFGS\":\n",
    "    optimizer_ = optim.LBFGS(my_network.parameters(), lr=0.1, max_iter=1, max_eval=50000, tolerance_change=1.0 * np.finfo(float).eps)\n",
    "else:\n",
    "    raise ValueError(\"Optimizer not recognized\")\n",
    "    \n",
    "def fit(model, training_set, interior, num_epochs, optimizer, p, verbose=True):\n",
    "    history = list()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        if verbose: print(\"################################ \", epoch, \" ################################\")\n",
    "\n",
    "        running_loss = list([0])\n",
    "        \n",
    "        # Loop over batches\n",
    "        for j, (initial, w_initial, w_initial_t, bd_left,  bd_right) in enumerate(training_set):\n",
    "            \n",
    "            def closure():\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                                \n",
    "                bd_left.requires_grad = True\n",
    "                bd_right.requires_grad = True\n",
    "                # for initial\n",
    "                initial.requires_grad = True\n",
    "                w_initial_pred_ = model(initial)\n",
    "                u_initial_pred_ = w_initial_pred_[:,0].reshape(-1,1)\n",
    "                p_initial_pred_ = w_initial_pred_[:,1].reshape(-1,1)\n",
    "                u1_initial_pred_ = w_initial_pred_[:,2].reshape(-1,1)\n",
    "                p1_initial_pred_ = w_initial_pred_[:,3].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                # with derivative\n",
    "                inpu = torch.ones(initial_pts, 1 )\n",
    "                \n",
    "                grad_u_ini = torch.autograd.grad(u_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                \n",
    "                u_initial_t = grad_u_ini[:, 1]\n",
    "                \n",
    "                \n",
    "                grad_p_ini = torch.autograd.grad(p_initial_pred_, initial, grad_outputs=inpu, create_graph=True)[0]\n",
    "                \n",
    "                p_initial_t = grad_p_ini[:, 1]\n",
    "                \n",
    "                grad_u1_ini = torch.autograd.grad(u1_initial_pred_, initial, grad_outputs=inpu, create_graph=True, allow_unused=True)[0]\n",
    "                \n",
    "                u1_initial_t = grad_u1_ini[:, 1]\n",
    "                \n",
    "                \n",
    "                grad_p1_ini = torch.autograd.grad(p1_initial_pred_, initial, grad_outputs=inpu, create_graph=True)[0]\n",
    "                \n",
    "                p1_initial_t = grad_p1_ini[:, 1]\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "                # for left boundary\n",
    "                w_bd_left_pred_ = model(bd_left)\n",
    "                u_bd_left_pred_ = w_bd_left_pred_[:,0].reshape(-1,1)\n",
    "                p_bd_left_pred_ = w_bd_left_pred_[:,1].reshape(-1,1)\n",
    "                \n",
    "                u1_bd_left_pred_ = w_bd_left_pred_[:,2].reshape(-1,1)\n",
    "                p1_bd_left_pred_ = w_bd_left_pred_[:,3].reshape(-1,1)\n",
    "                \n",
    "                # for right boundary\n",
    "                w_bd_right_pred_ = model(bd_right)\n",
    "                u_bd_right_pred_ = w_bd_right_pred_[:,0].reshape(-1,1)\n",
    "                p_bd_right_pred_ = w_bd_right_pred_[:,1].reshape(-1,1)\n",
    "                \n",
    "                u1_bd_right_pred_ = w_bd_right_pred_[:,2].reshape(-1,1)\n",
    "                p1_bd_right_pred_ = w_bd_right_pred_[:,3].reshape(-1,1)\n",
    "                \n",
    "\n",
    "\n",
    "                inputs2 = torch.ones(left_boundary_pts, 1)\n",
    "                inputs3 = torch.ones(right_boundary_pts, 1)\n",
    "                grad_u_b_l = torch.autograd.grad(u_bd_left_pred_, bd_left, grad_outputs=inputs2, create_graph=True)[0]\n",
    "                grad_u_b_r = torch.autograd.grad(u_bd_right_pred_, bd_right, grad_outputs=inputs3, create_graph=True)[0]\n",
    "                u_b_l_x = grad_u_b_l[:, 0]\n",
    "                u_b_r_x = grad_u_b_r[:, 0]\n",
    "                \n",
    "                u_b_l_xx = torch.autograd.grad(u_b_l_x, bd_left, grad_outputs=torch.ones(bd_left.shape[0]), create_graph=True)[0]\n",
    "                u_bd_left_xx = u_b_l_xx[:, 0].reshape(-1,1)\n",
    "\n",
    "                u_b_r_xx = torch.autograd.grad(u_b_r_x, bd_right, grad_outputs=torch.ones(bd_right.shape[0]), create_graph=True)[0]\n",
    "                u_bd_right_xx = u_b_r_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                inputs4 = torch.ones(left_boundary_pts, 1)\n",
    "                inputs5 = torch.ones(right_boundary_pts, 1)\n",
    "                grad_v_b_l = torch.autograd.grad(p_bd_left_pred_, bd_left, grad_outputs=inputs4, create_graph=True)[0]\n",
    "                grad_v_b_r = torch.autograd.grad(p_bd_right_pred_, bd_right, grad_outputs=inputs5, create_graph=True)[0]\n",
    "                v_b_l_x = grad_v_b_l[:, 0]\n",
    "                v_b_r_x = grad_v_b_r[:, 0]\n",
    "                \n",
    "                v_b_l_xx = torch.autograd.grad(v_b_l_x, bd_left, grad_outputs=torch.ones(bd_left.shape[0]), create_graph=True)[0]\n",
    "                v_bd_left_xx = v_b_l_xx[:, 0].reshape(-1,1)\n",
    "\n",
    "                v_b_r_xx = torch.autograd.grad(v_b_r_x, bd_right, grad_outputs=torch.ones(bd_right.shape[0]), create_graph=True)[0]\n",
    "                v_bd_right_xx = v_b_r_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "               \n",
    "                # predicted force\n",
    "                # (1-torch.sin(interior[:, 0]))*torch.cos(interior[:, 1]).reshape(-1, )\n",
    "                \n",
    "                # residual calculation\n",
    "                interior.requires_grad = True\n",
    "                w_hat = model(interior)\n",
    "                u_hat = w_hat[:,0].reshape(-1,1)\n",
    "                p_hat = w_hat[:,1].reshape(-1,1)\n",
    "                u1_hat = w_hat[:,2].reshape(-1,1)\n",
    "                p1_hat = w_hat[:,3].reshape(-1,1)\n",
    "                \n",
    "                inputs = torch.ones(residual_pts, 1 )\n",
    "                inputs2 = torch.ones(residual_pts, 1)\n",
    "                grad_u_hat = torch.autograd.grad(u_hat.reshape(-1,1), interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u_x = grad_u_hat[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_u_hat_xx = torch.autograd.grad(u_x, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u_xx = grad_u_hat_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_u_hat_xxx = torch.autograd.grad(u_xx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u_xxx = grad_u_hat_xxx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_u_hat_xxxx = torch.autograd.grad(u_xxx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u_xxxx = grad_u_hat_xxxx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                grad_p_hat = torch.autograd.grad(p_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p_x = grad_p_hat[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_p_hat_xx = torch.autograd.grad(p_x, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p_xx = grad_p_hat_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_p_hat_xxx = torch.autograd.grad(p_xx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p_xxx = grad_p_hat_xxx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_p_hat_xxxx = torch.autograd.grad(p_xxx, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p_xxxx = grad_p_hat_xxxx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                grad_u1_hat = torch.autograd.grad(u1_hat.reshape(-1,1), interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u1_x = grad_u1_hat[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_u1_hat_xx = torch.autograd.grad(u1_x, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u1_xx = grad_u1_hat_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                grad_p1_hat = torch.autograd.grad(p1_hat, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p1_x = grad_p1_hat[:, 0].reshape(-1,1)\n",
    "                \n",
    "                grad_p1_hat_xx = torch.autograd.grad(p1_x, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p1_xx = grad_p1_hat_xx[:, 0].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #grad_grad_u_x = torch.autograd.grad(u_x, interior, grad_outputs=torch.ones(interior.shape[0]), create_graph=True)[0]\n",
    "                #u_xx = grad_grad_u_x[:, 0]\n",
    "                u_t = grad_u_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_u_hat_tt = torch.autograd.grad(u_t, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u_tt = grad_u_hat_tt[:, 1].reshape(-1,1)\n",
    "                \n",
    "                p_t = grad_p_hat[:,1].reshape(-1,1)\n",
    "                grad_p_hat_tt = torch.autograd.grad(p_t, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p_tt = grad_p_hat_tt[:, 1].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                u1_t = grad_u1_hat[:, 1].reshape(-1,1)\n",
    "                \n",
    "                grad_u1_hat_tt = torch.autograd.grad(u1_t, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                u1_tt = grad_u1_hat_tt[:, 1].reshape(-1,1)\n",
    "                \n",
    "                p1_t = grad_p1_hat[:,1].reshape(-1,1)\n",
    "                grad_p1_hat_tt = torch.autograd.grad(p1_t, interior, grad_outputs=inputs, create_graph=True)[0]\n",
    "                \n",
    "                p1_tt = grad_p1_hat_tt[:, 1].reshape(-1,1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # data\n",
    "                \n",
    "                u_data_pred1 = model(data_inp1)\n",
    "                \n",
    "                u_data_pred2 = model(data_inp2)\n",
    "                \n",
    "                u_data_pred3 = model(data_inp3)\n",
    "                \n",
    "                u_data_pred4 = model(data_inp4)\n",
    "               \n",
    "                u_data_pred5 = model(data_inp5)\n",
    "                \n",
    "                u_data_pred6 = model(data_inp6)\n",
    "                \n",
    "                u_data_pred7 = model(data_inp7)\n",
    "                \n",
    "                u_data_pred8 = model(data_inp8)\n",
    "                \n",
    "                u_data_pred9 = model(data_inp9)\n",
    "                \n",
    "                u_data_pred10 = model(data_inp10)\n",
    "                \n",
    "                u_data_pred11 = model(data_inp11)\n",
    "                \n",
    "                u_data_pred12 = model(data_inp12)\n",
    "                \n",
    "                u_data_pred13 = model(data_inp13)\n",
    "                \n",
    "                u_data_pred14 = model(data_inp14)\n",
    "                \n",
    "                # p_data and u_data\n",
    "                data = torch.mean((u_data_pred1[:,1].reshape(-1, )- data_p1.reshape(-1, ))**p) + torch.mean((u_data_pred4[:,1].reshape(-1, ) - data_p4.reshape(-1, ))**p)\n",
    "                data1 = torch.mean((u_data_pred1[:,0].reshape(-1, )- data_u1.reshape(-1, ))**p) + torch.mean((u_data_pred4[:,0].reshape(-1, ) - data_u4.reshape(-1, ))**p)\n",
    "                \n",
    "                data2 = torch.mean((u_data_pred14[:,1].reshape(-1, )- data_p14.reshape(-1, ))**p) +  torch.mean((u_data_pred12[:,1].reshape(-1, ) - data_p12.reshape(-1, ))**p)\n",
    "                data3 = torch.mean((u_data_pred14[:,0].reshape(-1, )- data_u14.reshape(-1, ))**p) + torch.mean((u_data_pred12[:,0].reshape(-1, ) - data_u12.reshape(-1, ))**p)\n",
    "                data4 =  torch.mean((u_data_pred8[:,1].reshape(-1, ) - data_p8.reshape(-1, ))**p) + torch.mean((u_data_pred10[:,1].reshape(-1, ) - data_p10.reshape(-1, ))**p) \n",
    "                data5 =  torch.mean((u_data_pred8[:,0].reshape(-1, ) - data_u8.reshape(-1, ))**p) + torch.mean((u_data_pred10[:,0].reshape(-1, ) - data_u10.reshape(-1, ))**p)\n",
    "                \n",
    "                # data_q and data_r\n",
    "                data6 = torch.mean((u_data_pred1[:,2].reshape(-1, )- data_q1.reshape(-1, ))**p) + torch.mean((u_data_pred4[:,2].reshape(-1, ) - data_q4.reshape(-1, ))**p)\n",
    "                data7 = torch.mean((u_data_pred1[:,3].reshape(-1, )- data_r1.reshape(-1, ))**p) + torch.mean((u_data_pred4[:,3].reshape(-1, ) - data_r4.reshape(-1, ))**p)\n",
    "                \n",
    "                data8 = torch.mean((u_data_pred14[:,2].reshape(-1, )- data_q14.reshape(-1, ))**p) +  torch.mean((u_data_pred12[:,2].reshape(-1, ) - data_q12.reshape(-1, ))**p)\n",
    "                data9 = torch.mean((u_data_pred14[:,3].reshape(-1, )- data_r14.reshape(-1, ))**p) + torch.mean((u_data_pred12[:,3].reshape(-1, ) - data_r12.reshape(-1, ))**p)\n",
    "                data10 =  torch.mean((u_data_pred8[:,2].reshape(-1, ) - data_q8.reshape(-1, ))**p) + torch.mean((u_data_pred10[:,2].reshape(-1, ) - data_q10.reshape(-1, ))**p) \n",
    "                data11 =  torch.mean((u_data_pred8[:,3].reshape(-1, ) - data_r8.reshape(-1, ))**p) + torch.mean((u_data_pred10[:,3].reshape(-1, ) - data_r10.reshape(-1, ))**p)\n",
    "                \n",
    "                   \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Item 1. below\n",
    "                loss1 = torch.mean((u_initial_t.reshape(-1, ) - w_initial_t[:,0].reshape(-1, ))**p)+torch.mean((u_initial_pred_.reshape(-1, ) - w_initial[:,0].reshape(-1, ))**p) + torch.mean((u_x.reshape(-1, ) - p_xx.reshape(-1, ) + w_hat[:, 4]*p_tt.reshape(-1, ) + p_hat.reshape(-1, )-p1_hat.reshape(-1, ) - (1-torch.sin(interior[:, 0]))*torch.cos(interior[:, 1]).reshape(-1,))**p) + torch.mean((u_bd_left_pred_.reshape(-1,)- u_b_l.reshape(-1,))**p) + torch.mean((u_bd_right_pred_.reshape(-1,)- u_b_r.reshape(-1,))**p)\n",
    "                \n",
    "                \n",
    "                loss2 = torch.mean((p_initial_pred_.reshape(-1, ) - w_initial[:,1].reshape(-1, ))**p)+ torch.mean((p_initial_t.reshape(-1, ) - w_initial_t[:,1].reshape(-1, ))**p) + torch.mean((u_xx.reshape(-1, )  + p_x.reshape(-1, ) - u_tt.reshape(-1, ) - u_hat.reshape(-1, ))**p)+torch.mean((p_bd_left_pred_.reshape(-1,)- p_b_l.reshape(-1,))**p) + torch.mean((p_bd_right_pred_.reshape(-1,)- p_b_r.reshape(-1,))**p)\n",
    "\n",
    "                loss3 = torch.mean((u1_initial_t.reshape(-1, ) - w_initial_t[:,2].reshape(-1, ))**p)+torch.mean((u1_initial_pred_.reshape(-1, ) - w_initial[:,2].reshape(-1, ))**p) + torch.mean((u1_x.reshape(-1, ) - p1_xx.reshape(-1, ) + p1_tt.reshape(-1, ) + p1_hat.reshape(-1, ) - p_hat.reshape(-1, ).reshape(-1, )-(2/pi)*torch.cos(interior[:, 1])+pi/2*torch.sin(interior[:,0])*torch.cos(interior[:, 1]))**p) + torch.mean((u1_bd_left_pred_.reshape(-1,))**p) + torch.mean((u1_bd_right_pred_.reshape(-1,))**p)\n",
    "                \n",
    "                loss4 = torch.mean((p1_initial_pred_.reshape(-1, ) - w_initial[:,3].reshape(-1, ))**p)+ torch.mean((p1_initial_t.reshape(-1, ) - w_initial_t[:,3].reshape(-1, ))**p) + torch.mean((u1_xx.reshape(-1, )  + p1_x.reshape(-1, ) - u1_tt.reshape(-1, ) - u1_hat.reshape(-1, ))**p)+torch.mean((p1_bd_left_pred_.reshape(-1,))**p) + torch.mean((p1_bd_right_pred_.reshape(-1,))**p)\n",
    "                \n",
    "\n",
    "\n",
    "                loss = loss1 + loss2 + loss3 + loss4  + data8 \n",
    "                #loss = torch.max(torch.abs((u_initial_pred_.reshape(-1, ) - u_initial.reshape(-1, )))) + torch.max(torch.abs((u_t.reshape(-1, ) - u_xx.reshape(-1, ))))+torch.max(torch.abs((u_bd_left_pred_.reshape(-1,)))) + torch.max(torch.abs((u_bd_right_pred_.reshape(-1,))))\n",
    " \n",
    "                # + data6  ++ data8\n",
    "                # Item 2. below\n",
    "                loss.backward()\n",
    "                # Compute average training loss over batches for the current epoch\n",
    "                running_loss[0] += loss.item()\n",
    "                return loss\n",
    "            \n",
    "            # Item 3. below\n",
    "            optimizer.step(closure=closure)\n",
    "            \n",
    "        print('Loss: ', (running_loss[0] / len(training_set)))\n",
    "        history.append(running_loss[0])\n",
    "\n",
    "    return history\n",
    "n_epochs = 2500\n",
    "#history = fit(my_network, training_set, interior, n_epochs, optimizer_, p=2, verbose=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "talented-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (activation): Tanh()\n",
       "  (input_layer): Linear(in_features=2, out_features=20, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (1): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (3): Linear(in_features=20, out_features=20, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=20, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving and loading Model\n",
    "FILE = \"model_parameter.pth\"\n",
    "#torch.save(my_network, FILE)\n",
    "\n",
    "# uncomment below when you need to test for different points\n",
    "my_network = torch.load(FILE)\n",
    "my_network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605b2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "backed-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1-torch.sin(interior[:, 0]))*torch.cos(interior[:, 1]).reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hydraulic-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.linspace(0, pi, 10000).reshape(-1,1)\n",
    "t_test = 0.5*torch.ones((10000,1))\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "w_test_pred = my_network(test)\n",
    "pred = w_test_pred[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "620d9196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0208, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_test = torch.linspace(0, pi, 10000).reshape(-1,1)\n",
    "t_test = 0.5*torch.ones((10000,1))\n",
    "test = torch.cat([x_test, t_test],1)\n",
    "w_test_pred = my_network(test)\n",
    "k =  w_test_pred[:,4]\n",
    "print( torch.mean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cebb9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.0208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef7249d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f6c1ee",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cd39f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551f1671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d6e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4cab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dfa2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01590b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691d04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0275006a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6873c489",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
